\documentclass[11pt]{article}
\usepackage{bookmark}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{color}
\usepackage{comment}
\usepackage{float}
\usepackage{graphicx}
%\usepackage[hidelinks]{hyperref}
\usepackage{makecell}
\usepackage[caption=false,font=footnotesize,subrefformat=parens,labelformat=parens]{subfig}
\usepackage{wrapfig}
\usepackage{url}
\usepackage[table]{xcolor}
%
\setlength{\parindent}{0.25in}
\setlength{\parskip}{.05in}
\pagestyle{plain}
%Title, date an author of the document
\title{Progress Report}
\author{Bardia Mojra}


\begin{document}
\maketitle
\thispagestyle{empty}

\bigskip
\bigskip
\begin{center}
      Robotic Vision Lab
\end{center}

\begin{center}
      The University of Texas at Arlington
\end{center}

\newpage

\section{To Do}
\begin{itemize}
      \item Implement pose estimation: implement basic object detection and
            feature extraction using YCB dataset.
      \item Implement uncertainty.
      \item Implement DOPE with added dropout before each layer to estimate
            variational Bayesian inference.
      \item Read Data Association and Localization of Classified Objects in Visual
            SLAM \cite{iqbal2020data}: in progress.
      \item Work on Pose Estimation Uncertainty paper.
      \item Implement PoseCNN, DOPE, and BayesOD.
      \item Look into domain randomization and adaptation techniques.
      \item Search for recent pose estimation survey papers: Found this paper,
            \cite{du2020vision}, on pose estimation.
      \item As I read more papers, go back and update Pose Estimation Survey paper.
      \item Finish Tensorflow tutorials, \cite{CVTF2}: 4/9 chapters done.
      \item Learn to implement transfer learning.
      \item (On pause) Finish Docker tutorials, \cite{schenker2020learn}: 4/18
            chapters done.
\end{itemize}

\section{Literature Reviews}
\subsection{Obtaining Well Calibrated Probabilities Using Bayesian Binning}

\begin{itemize}
      \item code: \url{https://github.com/pakdaman/calibration/}
      \item paper: \url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4410090/}
      \item citation: \cite{naeini2015obtaining}
\end{itemize}

      \subsubsection{Introduction}
      \par In this paper, the authors propose a novel calibration method for
      probabilistic predictive models. Bayesian Binning into Qualities (BBQ),
      is a non-parametric and post-processing calibration method. Their
      proposed method is a binary classifier calibration method is based on the
      histogram-binning calibration method \cite{zadrozny2001obtaining}. It is
      important to note this method could be extended to multi-class
      classification tasks \cite{zadrozny2002transforming}.

      \subsubsection{Problem Statement}
      \par In machine learning, classification problems are often solved by deploying a
      a predictive model trained on some given data set but often underperform and
      make miscalibrated predictions ("classifier score"). Statistically speaking, for
      a calibrated prediction of i.e. 40\%, there will be an occurrence of 40\% for a
      give test set that is 1) large enough with respect to solution space size, 2)
      test data set is randomly selected (for more insight read on
      \textit{Central Limit Theorem}.

      Figure 1 is a reliability curve \cite{degroot1983comparison}
      \cite{niculescu2005predicting} that is used as an example of a predictive
      model with poorly estimated probabilities.

      %\write18{wget https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4410090/bin/nihms679964f1.jpg}
      %\includegraphics[with=\textwidth]{./nihms679964f1.jpg}

      \subsubsection{Related Work}
      \par Mainly, calibration is done two ways 1) \textit{ab initio}, by modifying
      objective function which increases computational cost. 2) It can be done as a
      post-processing procedure. Post processing can be categorized into parametric
      and non-parametric. Platt's method is an example of parametric calibration,
      \cite{platt1999probabilistic}. Non-parametric methods include histogram-
      binning \cite{zadrozny2001obtaining}, Platt scaling
      \cite{platt1999probabilistic}, and isotonic regression
      \cite{zadrozny2002transforming}.

      \subsubsection{Method}
      \par BBQ is an extension of simple histogram binning method
      \cite{zadrozny2001obtaining}, with added capability to consider different
      binning models (different number of bins) and their combinations under a
      Bayesian framework \cite{heckerman1995learning}. The generated Bayesian
      score provides further insight into network structure and it is also used
      when combining binning models.

      $$ \textit{Score}(M) ~=~ P(M)~.~P(D | M) $$

      The marginal likelihood, $P(D | M)$, has a closed form solution under the
      following 3 conditions, \cite{heckerman1995learning}:

      \begin{enumerate}
            \item All samples are under i.i.d. assumption and the class
            distribution $P(Z|B=b)$, which is class distribution for bin b,
            with a binomial distribution with parameter $\theta_b$.
            \item Bin distributions are independent.
            \item The prior distribution over binning model parameters $\theta$'s
            are modeled using a Beta distribution.
      \end{enumerate}

      Marginal likelihood in closed form, \cite{heckerman1995learning}:

      $$
      P(D|M) = \prod_{b=1}^{B} \frac{\Gamma(\frac{N'}{B})}{\Gamma (N_b + \frac{N'}{B})}
      \frac{\Gamma (m_b + \alpha_b)}{\Gamma (\alpha_b)}
      \frac{\Gamma (n_b + \beta_b)}{\Gamma (\beta_b)}
      $$

      Where:
      \begin{itemize}
      \item $\Gamma(n) = (n-1)!$
      \item $N_b$: The total number of training instances in the $b$'th bin.
      \item $n_b$: The total instances of class \textit{zero} among all training
      instances $N_b$.
      \item $m_b$: The total instances of class \textit{one} among all training
      instances $N_b$.
      \item $P(M)$: The prior distribution of binning model M, uniform
      distribution for initial condition.
      \end{itemize}

      \par The above equation is used for model averaging by BBQ, they point
      out that mentioned Bayesian scores could be used for model selection. Per
      \cite{hoeting1999bayesian}, model averaging is superior to model
      selection methods.

      \subsubsection{BBQ}
      BBQ framework defines calibrated prediction as:

      $$
      P(z=1|y) = \sum_{i=1}^{T} \frac{\textit{Score}(M_i)}{\sum_{j=1}^{T} \textit{Score}(M_j)}
      ~.~ P(z=1 | y, M_i)
      $$

      Where:
      \begin{itemize}
            \item $T$ : total number of binning models considered
            \item $P(z=1 | y, M_i)$ : probability estimate using model $M_i$ for uncalibrated
      classifier output y.
      \end{itemize}


      \subsubsection{Calibration Measures}
      \begin{itemize}
            \item ECE: Expected Calibration Error is calculated over the bins.
            \item MCE: Maximum Calibration Error is calculated among the bins.
      \end{itemize}

      $$
      ECE = \sum_{i=1}^{K}P(i).|o_i - e_i| ~~,~~ MCE= \max\limits_{i=1}^{K}(|o_i-e_i|),
      $$

      Where:
      \begin{itemize}
            \item $o_i$: true fraction of positive instances in the i$^{th}$ bin.
            \item $e_i$: mean of the post-calibrated probabilities in the i$^{th}$ bin.
            \item $P(i)$: empirical probability (fraction) of all instances in the i$^{th}$ bin.

      \end{itemize}
      \subsubsection{Empirical Results}
      \begin{itemize}
            \item Acc: accuracy
            \item AUC: area under the ROC curve (receiver operator characteristic curve).
            \item RMSE
            \item ECE
            \item MCE
      \end{itemize}

\section{Progress}
The following items are listed in the order of priority:
\begin{itemize}
      \item Object Pose Estimation with Uncertainty: After talking to Chris, it
      seems like using Tensorflow Graphics module may not be the simplest
      route. He recommended using  OpenCV and NumPy for import-export and
      processing, respectively. I have some familiarity with both modules and
      it seems straight forward.

      I recently learned a better way to keep track of my environment
      requirements. Python package manager (Pip) and Anaconda have built-in
      tools that if used properly could solve a large portion of my issues.
      There are features where once the environment is setup and operation,
      you can list and log all installed package with complete version number.
      This way I won't have to deal with Docker, for now at least.

      \item YCB Dataset \cite{calli2015ycb}: I converted the provided download
      script from Python 2 to Python 3 and added it to the repository. I will
      use YCB as my main realistic dataset. I will have to some sort of
      semantic segmentation to isolate each object. For now, I can use
      pixel-wise Hough voting but later I will change to the method used by
      \cite{Wang_2019_CVPR}.

      \item Pose Estimation in Simulation: Chris recommended Nvidia Isaac SDK
      \cite{NVIDIAIs75:online} and seems fairly realistic and is developed by
      Nvidia to tackle the \textit{sim-to-reality} problem. Given my limited
      processing power and skillset, it seems to be a more feasible approach in
      comparison to using Unreal Engine.

      \item Implement features from PoseCNN, DOPE, and BayesOD.
      \item Look into domain randomization and adaptation techniques.
      \item Search for recent pose estimation survey papers: Found this paper,
      \cite{du2020vision}, on pose estimation.

\end{itemize}

%\newpage

\section{Plans}
The following items are listed in the order of priority:

\begin{itemize}
      \item Use Nvidia Isaac SDK for pose estimation training.
      \item Keep working on Bayesian Pose Estimation paper.
      \item ARIAC: For now, I will focus on implementing pose estimation and
            BayesOD implementations.
      \item Continue on UE4 tutorials.
      \item Pose Estimation Survey Paper Feedback: On hold, I am working on
            Bayesian Pose Estimation.
      \item Project Alpe with Nolan: On pause for right now.
      \item UR5e: Finish ROS Industrial tutorials.
\end{itemize}

\section{2021 Goals and Target Journals/Conferences}
\begin{itemize}
      \item Submit a paper on pose estimation with uncertainty to ICIRS.
      \item Get comfortable with TensorFlow and related Python modules.
      \item Keep writing.
\end{itemize}


%Sets the bibliography style to UNSRT and import the
\newpage
\bibliography{references}
\bibliographystyle{ieeetr}

\end{document}
