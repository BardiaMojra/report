\documentclass[11pt]{article}
\usepackage{bookmark}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{color}
\usepackage{comment}
\usepackage{float}
\usepackage{graphicx}
%\usepackage[hidelinks]{hyperref}
\usepackage{makecell}
\usepackage[caption=false,font=footnotesize,subrefformat=parens,labelformat=parens]{subfig}
\usepackage{wrapfig}
\usepackage{url}
\usepackage[table]{xcolor}
%
\setlength{\parindent}{0.25in}
\setlength{\parskip}{.05in}
\pagestyle{plain}
%Title, date an author of the document
\title{Progress Report}
\author{Bardia Mojra}


\begin{document}
\maketitle
\thispagestyle{empty}

\begin{center}
	\bigskip
	\bigskip
	Robotic Vision Lab

	University of Texas at Arlington
\end{center}

\newpage

\section{To Do}
\begin{itemize}
	\item Look into transfer learning
\end{itemize}


\section{Progress}
Following items are listed in order of priority:
\begin{itemize}

	\item Pose Estimation: This week I dissected \cite{Dope} and wrote a literature review. The notes are on my Task Manager OneNote. Dope uses synthesized data for training their model and they works on so-called reality gap. Reality gap occurs when a model is trained on simulated data and tested in real environment and is characterized by models failure to perform as well as expected based on simulation dataset.
	      Dope uses Domain Randomization (DR) as a feasible solution to reality gap problem. Authors used Falling Things synthetic dataset and well as their own and combined DR images with photorealistic images to yield better training results than using only DR dataset. In essence, Dope is deep neural network that infer the 2D coordinates of projected 3D bounding boxes and then derives the 3D coordinates using EPnP.
	      In their approach, first they estimate a belief map of 2D keypoints of
	      all objects of interest in the image coordinate system. In the second
	      stage they compute (EPnP) 6D pose estimate based on the most likelihood
	      estimate (MLE) from the previous step.
	      Moreover for training, developers generated their ground truth training
	      data in simulation using Unreal Engine as oppose to PoseCNN's training
	      data, YCB data set, which is a set of high resolution scanned items limited to few objects and training images. DOPE's data set is much larger and allows for much deeper neural net training. It is also embedded or fused with eight intercepting lines from camera's focal point to the eight corners of each object's bounding box and another line to the center of the box for each object.

	\item OCRTOC: Jerry helped me setup a Docker container for DOPE but we need to convert the code from python v2 to v3. I also need to install Unreal Engine on my laptop and start modifying the dataset with Nvidia's NDDS plugin to generate our own embeddings. I think with additional
	      embeddings we can achieve better results or at least broaden the
	      application range. Moreover, I am almost out of space on my laptop so I am going to upgrade it with a 2TB M2 drive and perhaps an additional 2TB SSD for Windows and internal backup. Unreal Engine alone needs about
	      150GB, Matlab is another 50GB. I see why robotics is going more towards deep learning and that maybe because it is too difficult for most to derive equations of motion a simple LTI system.

	\item Reading list: \cite{lampinen2001bayesian} and \cite{li2019survey}.

	\item MoreFusion \cite{MoreFusion}: Still need to write a literature review on this.

	\item Project Alpe with Nolan: Nolan and I met today and discussed the direction of this side project. We don't want to spend more than 2-3 hours a week on this and we want to make it as productive as possible. Our objective is to record one-hour bi-weekly podcast on computer vision, AI and robotics where we discuss papers we read, what we learned recently and some of our projects. We will each create a professional website and incrementally post about our academic progress.

	\item TensorFlow: Now that I have some clue what I am doing in regards to pose estimation, I am shifting more time to implementation. I am working on chapter 2 on \cite{planche2019hands} which begins with a computer vision example using TensorFlow and Keras. I will try to finish it by end of the weekend. Everything makes more sense now, even when I review previous notes and reports I find new connections and familiar patterns.

	\item Quaternions: I think I understand this much better now. I don't think Hamilton intended to describe a 4th spatial dimension as described by some sources. I believe 6D and 7D notations are merely to simplify complex calculation. It is much easer to describe motion of an object with an additional variable term (a new mathematical dimension) than to calculate it for every instance using differentials of position with respect to time. It is an abstractions technique similar to the 3 angular "dimensions".

	\item UR5e:

	\item Fellowship:




\end{itemize}

\newpage

\section{Plans}
Following items are listed in order of priority:

\begin{itemize}

	\item (On pause) Continue with ROS Industrial tutorials and documentation.

	\item (On pause) Resume Robotic Perception course as soon as possible.

	\item (On pause) Read Digital Image Processing by Gonzalez and Woods.

\end{itemize}



%Sets the bibliography style to UNSRT and import the
\newpage
\bibliography{bib_BardiaMojra_dd-mm2020}
\bibliographystyle{ieeetr}

\end{document}
