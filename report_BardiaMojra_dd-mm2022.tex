\documentclass[11pt]{article}
\usepackage{bookmark}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{color}
\usepackage{comment}
\usepackage{float}
\usepackage{graphicx}
%\usepackage[hidelinks]{hyperref}
\usepackage{makecell}
\usepackage[caption=false,font=footnotesize,subrefformat=parens,labelformat=parens]{subfig}
\usepackage{wrapfig}
\usepackage{url}
\usepackage[table]{xcolor}
\graphicspath{{images_dd-mm2022/}}
\setlength{\parindent}{0.25in}
\setlength{\parskip}{.05in}
\pagestyle{plain}
%Title, date an author of the document
\title{Progress Report}
\author{Bardia Mojra}


\begin{document}
\maketitle
\thispagestyle{empty}

\bigskip
\bigskip
\begin{center}
 Robotic Vision Lab
\end{center}

\begin{center}
The University of Texas at Arlington
\end{center}

\newpage

\section{Research Plan}
This section outlines my current research plan where the main ideas, target
conference/journal, and expected date of completion for each paper
are provided.
Target conferences: ICRA, IROS (March), CASE (Late Feb.), NIPS.
Target Journals: RAL, CVPR, CORAL.

\begin{itemize}
  \item Koopman-01 (\textcolor{red}{IROS - Dec. 1st - active}):
  Koopman-based MPC control of VTOL-DIP and VTOL-TIP in simulation,
  DLO pose estimation in simulation,
  experiments on choice of basis function and lifting dimensions,
  and performance comparison with optimal, robust, and/or
  adaptive control schemes.\
  \item Koopman-02 (\textcolor{red}{ACC - Sep 30th - active}):
  A review on Koopman-based control schemes. \textcolor{red}{Not enough, make
  it part of another paper.} Read papers and write literature reviews.\

  \item Koopman-03 (\textcolor{black}{RAL - Mar. 1st - status}):
  Extension to Koopman-01, Koopman-based dynamic estimation of DLO,
  collect dynamic DLO dataset,
  prediction of DLO configuration.

  \item Quest-01 (\textcolor{orange}{IROS - Mar. 1st - next}):
  Optimal transform solution for QuEst based on dominant mode decomposition (DMD).
  \item Quest-02 (\textcolor{black}{IROS/RAL - date - status}):
  QuEst-based EKF, structure from motion, and VSLAM, compare performance with
  existing methods.
  \item Koopman-04 (\textcolor{black}{IROS/RAL - date - status}):
  Physics Informed (PI) Koopman-based control of a DLO,
  show obtained is persistant, compare to other non-PI methods, offline-online learning.
  \item Koopman-05 (\textcolor{black}{IROS/RAL - date - status}):
  PI Koopman operator (PIKO) based persistant model for DLOs, low dimensional,
  compare performance, offline-online learing/adapting, fast transfer learning.
  \item Koopman-06 (\textcolor{black}{IROS/RAL - date - status}):
  PIKO-based unit segment model for DLOs, more generalized, should yield better
  performance if number segments are selected online in order to
  obtain optimal representation in real-time given available hardware, compare
  results.
  \item Koopman-07 (\textcolor{black}{IROS/RAL - date - status}):
  DLO dataset, PIKO-based reinforcement learning of real DLO dynamics in a
  digital twin (DT) setting,
  experiments of model persistance, compare learning rate
  with neural network based methods, compare performance with available methods,
  and experiments on learing limitations.
  \item Koopman-08 (\textcolor{black}{IROS/RAL - date - status}):
  Koopman-based real-time control of DLO on GPU.
  \item Koopman-09 (\textcolor{black}{IROS/RAL - date - status}):
  PIKO-based real-time control of DLO on GPU.
  \item Koopman-10 (\textcolor{black}{IROS/RAL - date - status}):
  PIKO-based real-time control of deformable planar objects (DPO).
  \item Koopman-11 (\textcolor{black}{IROS/RAL - date - status}):
  PIKO-based real-time control of deformable volume objects (DVO).
  \item Koopman-12 (\textcolor{black}{IROS/RAL - date - status}):
  PIKO-based unit segment for DPOs, on GPU.
  \item Koopman-13 (\textcolor{black}{IROS/RAL - date - status}):
  PIKO-based unit segment for DVOs, on GPU.
\end{itemize}

\section{To Do}
\begin{itemize}
  \item QEKF Paper (\textcolor{red}{On pause}):
  \begin{itemize}
      \item Noise issue: noise cannot be modeled - DMD is a robust noise on high dimensional orthonormal time series and should be able to denoise QuEst solutions.
      \item SfM: RQuEst cannot find solution - A potential solution is described  briefly above.
  \end{itemize}
  \item  DLO Manipulation: (\textcolor{red}{ICRA - section out of date})
  \begin{itemize}
      \item Setup digital twin reinforcement learing setup:
      \begin{itemize}
        \item Unity Robotics extension setup -- done.
        \item Design dynamic DLO data collection system.
        \item Build work cell. -- done
        \item Collect data and create a dataset.
        \item Define evaluation metrics.
        \item Create a high frequency RGBD dataset with UV-frames and open-loop input control actions as the ground truth.
      \end{itemize}
      \item Real-Time Preception -- on hold
      \item Learning DLO Dynamics and System Identification - PIKO - On-going
  \end{itemize}
\end{itemize}

\newpage
\section{Progress}
The following items are listed in the order of priority:
\begin{itemize}
    \item DLO Manipulation (\textcolor{red}{IROS}):
    Last week, I looked into SimScape code API so it can be integrated into
    our code. It has a learning curve that could delay our progress. Dr. Gans
    and I decided to set that aside in the interest of implementing and
    experimenting with a cart-pendulum system. I implemented the model and
    associated Koopman operator controller. The model is a classical explicit
    dynamical expression. However, the controller is different. In their seminal
    work the authors, Ian Abraham and Tod Murphy, define two mapping functions
    for state and input, respectively. The state, $x(t)->z(x(t))$ is lifted
    from 4 to 7. Then, they consider an observable function $x(t),u(t)->v(x(t),u(t))$,
    and provided its derivatives $dv/du$ and $dv/dz$. They define a \emph{general
    objective function} with a \emph{differentiable policy}. They use a technique
    called \emph{mode insertion gradient} which, I do not understand at this time.
    This is too advanced and I only stared reading this part on Friday, so I do
    not fully understand it. They analytically derive a \emph{Control Hamiltonian
    with the input integrated}. This allows for optimal control with the input
    and significantly reduced the training time. Moreover, they extend this
    with an active learner which, I have not looked into.
    \emph{Active-Koopman} is a separate paper \cite{abraham2019active} from
    \cite{abraham2017model} which, we were originally following but the explanation
    did not make sense for the cart-pendulum example.
    I ported the code in and I am stepping through it. I don't believe the code
    I ported in was the active learning example because they provide a separate
    example for that but I am not sure. In the code, the policy is actively
    updated.  \\
    \item Maicol (REU): I want him to start working on Omniverse and Isaac Sim
    tutorials, at his leasure. I believe having someone on the team who is
    familiar with these development environments brings considerable value to
    the team and particularly my own research.\\
    \item DoD SMART (\textcolor{red}{Dec 1st.}): I started the application.\\
    \item XEst (\textcolor{red}{RAL ---}): No update.\\
  \end{itemize}
\newpage

%Sets the bibliography style to UNSRT and import the
\newpage
\bibliography{ref}
\bibliographystyle{ieeetr}

\end{document}
